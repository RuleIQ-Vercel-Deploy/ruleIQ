#!/usr/bin/env python3
"""Standalone test for golden dataset ingestion - bypasses import issues."""

import os
import sys

# Set environment variables FIRST
os.environ["NEO4J_URI"] = "bolt://localhost:7688"
os.environ["NEO4J_USER"] = "neo4j"
os.environ["NEO4J_PASSWORD"] = "ruleiq123"

# Add path but don't import anything that might override env vars
sys.path.insert(0, ".")


def test_direct_neo4j():
    """Test Neo4j connection directly without any problematic imports."""
    from neo4j import GraphDatabase

    print("üîå Testing direct Neo4j connection...")
    print(f"  URI: {os.environ['NEO4J_URI']}")
    print(f"  User: {os.environ['NEO4J_USER']}")
    print(f"  Password: {os.environ['NEO4J_PASSWORD']}")

    try:
        driver = GraphDatabase.driver(
            os.environ["NEO4J_URI"],
            auth=(os.environ["NEO4J_USER"], os.environ["NEO4J_PASSWORD"]),
        )

        with driver.session() as session:
            # Test connection
            result = session.run("RETURN 1 as test")
            print(f"‚úÖ Connection successful: {result.single()['test']}")

            # Create the VECTOR index if it doesn't exist
            print("\nüìä Creating VECTOR index for golden dataset...")
            try:
                session.run(
                    """
                    CREATE VECTOR INDEX golden_chunk_embeddings IF NOT EXISTS
                    FOR (c:GoldenChunk)
                    ON (c.embedding)
                    OPTIONS {
                        indexConfig: {
                            `vector.dimensions`: 384,
                            `vector.similarity_function`: 'cosine',
                        },
                    }
                """,
                )
                print("‚úÖ VECTOR index created/verified")
            except Exception as e:
                print(f"‚ö†Ô∏è Index might already exist: {e}")

            # Ingest sample data directly
            print("\nüì• Ingesting sample golden dataset...")

            # Sample document 1
            result = session.run(
                """
                CREATE (d:GoldenDocument {
                    doc_id: 'gdpr_article_5',
                    content: 'GDPR Article 5: Principles relating to processing of personal data. Personal data shall be processed lawfully, fairly and in a transparent manner.',
                    source: 'GDPR',
                    created_at: datetime()
                })
                RETURN d.doc_id as id
            """,
            )
            print(f"‚úÖ Created document: {result.single()['id']}")

            # Sample chunk with embedding
            import numpy as np

            embedding = np.random.rand(384).tolist()  # Mock embedding

            result = session.run(
                """
                MATCH (d:GoldenDocument {doc_id: 'gdpr_article_5'})
                CREATE (c:GoldenChunk {
                    chunk_id: 'gdpr_article_5_chunk_1',
                    content: 'Personal data shall be processed lawfully, fairly and in a transparent manner.',
                    embedding: $embedding,
                    created_at: datetime()
                })
                CREATE (d)-[:HAS_CHUNK]->(c)
                RETURN c.chunk_id as id
            """,
                embedding=embedding,
            )
            print(f"‚úÖ Created chunk with embedding: {result.single()['id']}")

            # Verify ingestion
            count_result = session.run(
                """
                MATCH (d:GoldenDocument)
                RETURN count(d) as doc_count
            """,
            )
            doc_count = count_result.single()["doc_count"]

            chunk_result = session.run(
                """
                MATCH (c:GoldenChunk)
                RETURN count(c) as chunk_count
            """,
            )
            chunk_count = chunk_result.single()["chunk_count"]

            print(f"\nüìä Current golden dataset status:")
            print(f"  - Documents: {doc_count}")
            print(f"  - Chunks: {chunk_count}")

            # Test vector search
            print("\nüîç Testing vector similarity search...")
            query_embedding = np.random.rand(384).tolist()

            result = session.run(
                """
                CALL db.index.vector.queryNodes(
                    'golden_chunk_embeddings',
                    3,
                    $query_embedding
                ) YIELD node, score
                RETURN node.chunk_id as chunk_id, score
                LIMIT 3
            """,
                query_embedding=query_embedding,
            )

            print("‚úÖ Vector search results:")
            for record in result:
                print(f"  - {record['chunk_id']}: score={record['score']:.4f}")

            # Clean up test data
            print("\nüßπ Cleaning up test data...")
            session.run(
                "MATCH (d:GoldenDocument {doc_id: 'gdpr_article_5'}) DETACH DELETE d",
            )
            print("‚úÖ Test data cleaned up")

        driver.close()
        print("\n‚úÖ All tests passed successfully!")
        return True

    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        import traceback

        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = test_direct_neo4j()
    sys.exit(0 if success else 1)
