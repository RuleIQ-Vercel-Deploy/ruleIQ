"""
Unit Tests for IQ Agent - Autonomous Compliance Orchestrator

Tests the IQ agent's GraphRAG compliance intelligence including:
- Intelligence loop (PERCEIVE → PLAN → ACT → LEARN → REMEMBER)
- Neo4j graph querying and pattern detection
- Memory management and consolidation
- Risk assessment and action planning
- Autonomous decision making within constraints
"""

import json
import os
import pytest
from datetime import datetime, timedelta
from unittest.mock import AsyncMock, Mock, patch, MagicMock
from uuid import uuid4

from services.iq_agent import IQComplianceAgent, IQAgentState, create_iq_agent
from services.neo4j_service import Neo4jGraphRAGService
from services.compliance_memory_manager import MemoryType, MemoryNode
from services.compliance_retrieval_queries import QueryCategory


@pytest.mark.unit
@pytest.mark.ai
@pytest.mark.asyncio
class TestIQComplianceAgent:
    """Test IQ Agent core functionality"""

    @pytest.fixture
    async def mock_neo4j_service(self):
        """Mock Neo4j service for testing"""
        service = Mock(spec=Neo4jGraphRAGService)
        service.connect = AsyncMock()
        service.close = AsyncMock()
        service.execute_query = AsyncMock()
        service.test_connection = AsyncMock()
        service.get_graph_statistics = AsyncMock(return_value={"total_nodes": 100})
        return service

    @pytest.fixture
    async def mock_memory_manager(self):
        """Mock memory manager for testing"""
        manager = Mock()
        manager.store_conversation_memory = AsyncMock(return_value="mem_12345")
        manager.store_knowledge_graph_memory = AsyncMock(return_value="mem_67890")
        manager.retrieve_contextual_memories = AsyncMock()
        manager.consolidate_compliance_knowledge = AsyncMock(return_value={"status": "success"})
        return manager

    @pytest.fixture
    async def iq_agent(self, mock_neo4j_service):
        """Create IQ agent instance for testing"""
        with patch('services.iq_agent.ChatOpenAI') as mock_llm:
            mock_llm.return_value = Mock()
            agent = IQComplianceAgent(mock_neo4j_service)
            return agent

    async def test_agent_initialization(self, iq_agent):
        """Test IQ agent initializes correctly"""
        assert iq_agent is not None
        assert iq_agent.RISK_THRESHOLD == 7.0
        assert iq_agent.AUTONOMY_BUDGET == 10000.0
        assert iq_agent.system_prompt is not None
        assert "IQ — Autonomous Compliance Orchestrator" in iq_agent.system_prompt

    async def test_process_query_success(self, iq_agent):
        """Test successful query processing through intelligence loop"""
        query = "What are our GDPR compliance gaps?"
        
        # Mock the workflow execution
        mock_state = Mock()
        mock_state.compliance_posture = {
            "overall_coverage": 0.75,
            "total_gaps": 5,
            "critical_gaps": 2
        }
        mock_state.action_plan = [
            {
                "action_id": "action_1",
                "target": "Implement consent management",
                "priority": "critical",
                "graph_reference": "gap_123"
            }
        ]
        mock_state.risk_assessment = {"overall_risk_level": "MEDIUM"}
        mock_state.graph_context = {
            "coverage_analysis": [{"domain": "Data Protection"}],
            "compliance_gaps": [
                {
                    "gap_id": "gap_123",
                    "requirement": {"title": "Consent Management", "risk_level": "critical"},
                    "regulation": {"code": "GDPR"},
                    "domain": {"name": "Data Protection"}
                }
            ]
        }
        mock_state.evidence_collected = []
        mock_state.memories_accessed = ["mem_123"]
        mock_state.patterns_detected = []
        mock_state.messages = [Mock(content="Analysis complete")]

        with patch.object(iq_agent, 'workflow') as mock_workflow:
            mock_workflow.ainvoke = AsyncMock(return_value=mock_state)
            
            result = await iq_agent.process_query(query)
            
            assert result["status"] == "success"
            assert result["summary"]["compliance_score"] == 0.75
            assert result["summary"]["risk_posture"] in ["LOW", "MEDIUM", "HIGH", "CRITICAL"]
            assert len(result["summary"]["top_gaps"]) >= 0
            assert "artifacts" in result
            assert "graph_context" in result
            assert "evidence" in result
            assert "next_actions" in result

    async def test_process_query_error_handling(self, iq_agent):
        """Test error handling in query processing"""
        query = "Invalid query that causes error"
        
        with patch.object(iq_agent, 'workflow') as mock_workflow:
            mock_workflow.ainvoke = AsyncMock(side_effect=Exception("Test error"))
            
            result = await iq_agent.process_query(query)
            
            assert result["status"] == "error"
            assert "Test error" in result["error"]
            assert result["summary"]["risk_posture"] == "UNKNOWN"

    async def test_perceive_node_compliance_analysis(self, iq_agent):
        """Test PERCEIVE node - compliance posture analysis"""
        state = IQAgentState(
            current_query="What are our compliance gaps?",
            graph_context={},
            compliance_posture={},
            risk_assessment={},
            action_plan=[],
            evidence_collected=[],
            memories_accessed=[],
            patterns_detected=[],
            messages=[]
        )

        # Mock compliance query results
        mock_coverage_result = Mock()
        mock_coverage_result.data = [{"domain": "Data Protection", "coverage": 0.8}]
        mock_coverage_result.metadata = {"overall_coverage": 0.8}

        mock_gap_result = Mock()
        mock_gap_result.data = [
            {
                "gap_id": "gap_1",
                "requirement": {"title": "Consent Management", "risk_level": "high"},
                "regulation": {"code": "GDPR"}
            }
        ]
        mock_gap_result.metadata = {"total_gaps": 1, "critical_gaps": 0, "high_risk_gaps": 1}

        with patch('services.iq_agent.execute_compliance_query') as mock_query:
            mock_query.side_effect = [mock_coverage_result, mock_gap_result]
            
            result_state = await iq_agent._perceive_node(state)
            
            assert result_state.compliance_posture["overall_coverage"] == 0.8
            assert result_state.compliance_posture["total_gaps"] == 1
            assert result_state.compliance_posture["critical_gaps"] == 0
            assert "coverage_analysis" in result_state.graph_context

    async def test_plan_node_action_generation(self, iq_agent):
        """Test PLAN node - risk-weighted action planning"""
        state = IQAgentState(
            current_query="Create action plan for compliance gaps",
            graph_context={
                "compliance_gaps": [
                    {
                        "gap_id": "gap_1",
                        "requirement": {"title": "Consent Management", "risk_level": "critical"},
                        "regulation": {"code": "GDPR"},
                        "domain": {"name": "Data Protection"},
                        "gap_severity_score": 8.5
                    },
                    {
                        "gap_id": "gap_2", 
                        "requirement": {"title": "Data Retention", "risk_level": "medium"},
                        "regulation": {"code": "GDPR"},
                        "domain": {"name": "Data Protection"},
                        "gap_severity_score": 5.0
                    }
                ]
            },
            compliance_posture={"overall_coverage": 0.6},
            risk_assessment={},
            action_plan=[],
            evidence_collected=[],
            memories_accessed=[],
            patterns_detected=[],
            messages=[]
        )

        # Mock query results for planning
        mock_risk_result = Mock()
        mock_risk_result.data = [{"pattern": "high_risk_concentration"}]

        mock_temporal_result = Mock()
        mock_temporal_result.data = [{"change": "new_requirement"}]
        mock_temporal_result.metadata = {"recent_changes": 2}

        with patch('services.iq_agent.execute_compliance_query') as mock_query:
            mock_query.side_effect = [mock_risk_result, mock_temporal_result]
            
            result_state = await iq_agent._plan_node(state)
            
            assert len(result_state.action_plan) > 0
            # Check that critical gaps are prioritized first
            first_action = result_state.action_plan[0]
            assert first_action["target"] == "Consent Management"
            assert first_action["priority"] == "critical"
            assert first_action["regulation"] == "GDPR"
            assert "cost_estimate" in first_action
            assert "timeline" in first_action

    async def test_act_node_autonomous_execution(self, iq_agent):
        """Test ACT node - autonomous action execution"""
        state = IQAgentState(
            current_query="Execute compliance actions",
            graph_context={},
            compliance_posture={},
            risk_assessment={},
            action_plan=[
                {
                    "action_id": "action_1",
                    "priority": "high",
                    "severity_score": 6.0,  # Below threshold
                    "cost_estimate": 5000.0,  # Below budget
                    "target": "Implement consent management"
                },
                {
                    "action_id": "action_2", 
                    "priority": "critical",
                    "severity_score": 9.0,  # Above threshold
                    "cost_estimate": 15000.0,  # Above budget
                    "target": "Complete audit overhaul"
                }
            ],
            evidence_collected=[],
            memories_accessed=[],
            patterns_detected=[],
            messages=[]
        )

        # Mock execution methods
        iq_agent._should_auto_execute = AsyncMock(side_effect=[True, False])
        iq_agent._execute_action = AsyncMock(return_value={
            "action_id": "action_1",
            "status": "executed",
            "result": "success"
        })
        iq_agent._create_escalation = AsyncMock(return_value={
            "action_id": "action_2", 
            "status": "escalated",
            "reason": "Requires manual approval"
        })
        iq_agent._store_execution_evidence = AsyncMock()

        result_state = await iq_agent._act_node(state)
        
        assert len(result_state.evidence_collected) == 2
        executed_actions = [e for e in result_state.evidence_collected if e.get("status") == "executed"]
        escalated_actions = [e for e in result_state.evidence_collected if e.get("status") == "escalated"]
        
        assert len(executed_actions) == 1
        assert len(escalated_actions) == 1

    async def test_learn_node_pattern_detection(self, iq_agent):
        """Test LEARN node - pattern detection and knowledge updates"""
        state = IQAgentState(
            current_query="Learn from compliance execution",
            graph_context={
                "compliance_gaps": [
                    {"domain": {"name": "Data Protection"}},
                    {"domain": {"name": "Data Protection"}}, 
                    {"domain": {"name": "Data Protection"}},
                    {"domain": {"name": "Data Protection"}}  # 4 gaps in same domain
                ]
            },
            compliance_posture={},
            risk_assessment={},
            action_plan=[],
            evidence_collected=[
                {"action_id": "action_1", "status": "executed", "effectiveness": 0.9}
            ],
            memories_accessed=[],
            patterns_detected=[],
            messages=[]
        )

        # Mock enforcement learning query
        mock_enforcement_result = Mock()
        mock_enforcement_result.data = [{"case": "GDPR_violation", "lesson": "implement_consent"}]

        with patch('services.iq_agent.execute_compliance_query') as mock_query:
            mock_query.return_value = mock_enforcement_result
            
            result_state = await iq_agent._learn_node(state)
            
            assert len(result_state.patterns_detected) > 0
            # Check for high gap concentration pattern
            gap_pattern = next(
                (p for p in result_state.patterns_detected 
                 if p.get("pattern_type") == "HIGH_GAP_CONCENTRATION"), 
                None
            )
            assert gap_pattern is not None
            assert gap_pattern["domain"] == "Data Protection"
            assert gap_pattern["gap_count"] == 4

    async def test_remember_node_memory_consolidation(self, iq_agent, mock_memory_manager):
        """Test REMEMBER node - memory storage and consolidation"""
        iq_agent.memory_manager = mock_memory_manager
        
        state = IQAgentState(
            current_query="Remember compliance insights",
            graph_context={},
            compliance_posture={},
            risk_assessment={},
            action_plan=[],
            evidence_collected=[],
            memories_accessed=[],
            patterns_detected=[
                {"pattern_type": "HIGH_RISK", "confidence": 0.8}
            ],
            messages=[],
            step_count=10  # Trigger consolidation
        )

        # Mock memory retrieval
        mock_memory_result = Mock()
        mock_memory_result.retrieved_memories = [
            Mock(id="mem_1"),
            Mock(id="mem_2")
        ]
        mock_memory_manager.retrieve_contextual_memories.return_value = mock_memory_result

        result_state = await iq_agent._remember_node(state)
        
        # Verify memory operations were called
        mock_memory_manager.store_knowledge_graph_memory.assert_called()
        mock_memory_manager.retrieve_contextual_memories.assert_called()
        mock_memory_manager.consolidate_compliance_knowledge.assert_called()
        
        assert len(result_state.memories_accessed) == 2
        assert "knowledge_consolidation" in result_state.graph_context

    async def test_autonomy_decision_making(self, iq_agent):
        """Test autonomous decision making within risk/cost constraints"""
        # Test auto-execution criteria
        low_risk_action = {
            "severity_score": 5.0,  # Below threshold (7.0)
            "cost_estimate": 8000.0,  # Below budget (10000.0)
            "priority": "high"
        }
        assert await iq_agent._should_auto_execute(low_risk_action) == True

        high_risk_action = {
            "severity_score": 8.0,  # Above threshold
            "cost_estimate": 5000.0,  # Below budget
            "priority": "critical"
        }
        assert await iq_agent._should_auto_execute(high_risk_action) == False

        high_cost_action = {
            "severity_score": 5.0,  # Below threshold
            "cost_estimate": 15000.0,  # Above budget
            "priority": "high"
        }
        assert await iq_agent._should_auto_execute(high_cost_action) == False

    async def test_risk_posture_calculation(self, iq_agent):
        """Test risk posture determination logic"""
        # Critical risk scenario
        critical_posture = {"overall_coverage": 0.3, "critical_gaps": 6}
        critical_assessment = {"convergence_patterns": 12}
        risk = iq_agent._determine_risk_posture(critical_posture, critical_assessment)
        assert risk == "CRITICAL"

        # High risk scenario
        high_posture = {"overall_coverage": 0.6, "critical_gaps": 3}
        high_assessment = {"convergence_patterns": 7}
        risk = iq_agent._determine_risk_posture(high_posture, high_assessment)
        assert risk == "HIGH"

        # Medium risk scenario
        medium_posture = {"overall_coverage": 0.8, "critical_gaps": 1}
        medium_assessment = {"convergence_patterns": 2}
        risk = iq_agent._determine_risk_posture(medium_posture, medium_assessment)
        assert risk == "MEDIUM"

        # Low risk scenario
        low_posture = {"overall_coverage": 0.9, "critical_gaps": 0}
        low_assessment = {"convergence_patterns": 1}
        risk = iq_agent._determine_risk_posture(low_posture, low_assessment)
        assert risk == "LOW"

    async def test_regulation_code_extraction(self, iq_agent):
        """Test extraction of regulation codes from queries"""
        query1 = "What are our GDPR and 6AMLD compliance requirements?"
        codes1 = iq_agent._extract_regulation_codes(query1)
        assert "GDPR" in codes1
        assert "6AMLD" in codes1

        query2 = "How does DORA affect our operational risk controls?"
        codes2 = iq_agent._extract_regulation_codes(query2)
        assert "DORA" in codes2

        query3 = "General compliance question without specific regulations"
        codes3 = iq_agent._extract_regulation_codes(query3)
        assert len(codes3) == 0

    async def test_cost_and_timeline_estimation(self, iq_agent):
        """Test action cost and timeline estimation"""
        critical_gap = {
            "requirement": {"risk_level": "critical"}
        }
        cost = iq_agent._estimate_action_cost(critical_gap)
        timeline = iq_agent._estimate_timeline(critical_gap)
        
        assert cost == 15000.0  # base_cost * 3.0 multiplier
        assert timeline == "30_days"

        medium_gap = {
            "requirement": {"risk_level": "medium"}
        }
        cost = iq_agent._estimate_action_cost(medium_gap)
        timeline = iq_agent._estimate_timeline(medium_gap)
        
        assert cost == 7500.0  # base_cost * 1.5 multiplier
        assert timeline == "90_days"

    async def test_response_formatting(self, iq_agent):
        """Test proper response formatting according to contract"""
        mock_state = IQAgentState(
            current_query="Test query",
            graph_context={
                "coverage_analysis": [{"domain": "Test"}],
                "compliance_gaps": [
                    {"requirement": {"title": "Test Requirement 1"}},
                    {"requirement": {"title": "Test Requirement 2"}}
                ]
            },
            compliance_posture={"overall_coverage": 0.85},
            risk_assessment={},
            action_plan=[
                {"target": "Action 1", "priority": "high", "graph_reference": "ref_1"},
                {"target": "Action 2", "priority": "medium", "graph_reference": "ref_2"}
            ],
            evidence_collected=[
                {"status": "executed"},
                {"status": "escalated"}
            ],
            memories_accessed=["mem_1", "mem_2"],
            patterns_detected=[{"type": "pattern1"}],
            messages=[Mock(content="Test response")]
        )

        response = iq_agent._format_response(mock_state)
        
        # Verify required response structure
        assert response["status"] == "success"
        assert "timestamp" in response
        
        # Verify summary section
        summary = response["summary"]
        assert "risk_posture" in summary
        assert summary["compliance_score"] == 0.85
        assert len(summary["top_gaps"]) <= 3
        assert len(summary["immediate_actions"]) <= 3
        
        # Verify artifacts section
        artifacts = response["artifacts"]
        assert "compliance_posture" in artifacts
        assert "action_plan" in artifacts
        assert "risk_assessment" in artifacts
        
        # Verify graph_context section
        graph_context = response["graph_context"]
        assert graph_context["nodes_traversed"] == 1
        assert len(graph_context["patterns_detected"]) == 1
        assert len(graph_context["memories_accessed"]) == 2
        
        # Verify evidence section
        evidence = response["evidence"]
        assert evidence["controls_executed"] == 1
        assert evidence["evidence_stored"] == 2
        
        # Verify next_actions section
        next_actions = response["next_actions"]
        assert len(next_actions) <= 5
        assert all("action" in action for action in next_actions)
        assert all("priority" in action for action in next_actions)
        assert all("graph_reference" in action for action in next_actions)


@pytest.mark.integration
@pytest.mark.asyncio
class TestIQAgentIntegration:
    """Integration tests for IQ Agent with real components"""

    @pytest.fixture
    async def neo4j_service(self):
        """Create real Neo4j service for integration tests"""
        service = Neo4jGraphRAGService()
        await service.connect()
        yield service
        await service.close()

    @pytest.mark.skipif(
        not os.environ.get("NEO4J_URI"), 
        reason="Neo4j not configured for integration tests"
    )
    async def test_create_iq_agent_factory(self, neo4j_service):
        """Test IQ agent factory function with real Neo4j"""
        agent = await create_iq_agent(neo4j_service)
        
        assert agent is not None
        assert isinstance(agent, IQComplianceAgent)
        assert agent.neo4j == neo4j_service

    @pytest.mark.skipif(
        not os.environ.get("NEO4J_URI"),
        reason="Neo4j not configured for integration tests"
    )
    async def test_end_to_end_compliance_query(self, neo4j_service):
        """Test complete end-to-end compliance query processing"""
        agent = await create_iq_agent(neo4j_service)
        
        query = "What are our current GDPR compliance gaps?"
        
        with patch('services.iq_agent.ChatOpenAI') as mock_llm:
            mock_llm.return_value.ainvoke = AsyncMock(return_value=Mock(
                content="Based on the analysis, here are the key GDPR compliance gaps..."
            ))
            
            result = await agent.process_query(query)
            
            assert result["status"] == "success"
            assert "summary" in result
            assert "artifacts" in result
            assert "graph_context" in result
            assert result["llm_response"] is not None


@pytest.mark.performance
@pytest.mark.asyncio 
class TestIQAgentPerformance:
    """Performance tests for IQ Agent"""

    async def test_query_processing_performance(self, iq_agent):
        """Test query processing performance within acceptable limits"""
        import time
        
        query = "Analyze our compliance posture across all domains"
        
        # Mock fast responses
        with patch.object(iq_agent, 'workflow') as mock_workflow:
            mock_state = Mock()
            mock_state.compliance_posture = {"overall_coverage": 0.8}
            mock_state.action_plan = []
            mock_state.risk_assessment = {}
            mock_state.graph_context = {"coverage_analysis": []}
            mock_state.evidence_collected = []
            mock_state.memories_accessed = []
            mock_state.patterns_detected = []
            mock_state.messages = [Mock(content="Response")]
            
            mock_workflow.ainvoke = AsyncMock(return_value=mock_state)
            
            start_time = time.time()
            await iq_agent.process_query(query)
            end_time = time.time()
            
            processing_time = end_time - start_time
            # Should process within 5 seconds for mocked responses
            assert processing_time < 5.0

    async def test_memory_usage_efficiency(self, iq_agent):
        """Test memory usage doesn't grow excessively during processing"""
        import psutil
        import os
        
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss
        
        # Process multiple queries
        queries = [
            "What are our GDPR gaps?",
            "Analyze operational risk controls",
            "Review AML compliance status",
            "Check data protection measures"
        ]
        
        with patch.object(iq_agent, 'workflow') as mock_workflow:
            mock_state = Mock()
            mock_state.compliance_posture = {"overall_coverage": 0.8}
            mock_state.action_plan = []
            mock_state.risk_assessment = {}
            mock_state.graph_context = {"coverage_analysis": []}
            mock_state.evidence_collected = []
            mock_state.memories_accessed = []
            mock_state.patterns_detected = []
            mock_state.messages = [Mock(content="Response")]
            
            mock_workflow.ainvoke = AsyncMock(return_value=mock_state)
            
            for query in queries:
                await iq_agent.process_query(query)
        
        final_memory = process.memory_info().rss
        memory_growth = final_memory - initial_memory
        
        # Memory growth should be reasonable (less than 50MB for mocked processing)
        assert memory_growth < 50 * 1024 * 1024  # 50MB


if __name__ == "__main__":
    pytest.main([__file__, "-v"])