"""
Integration Tests for Evidence Classification API Endpoints

Tests the AI-powered evidence classification API endpoints with real database interactions.
"""

import json
from unittest.mock import patch
from uuid import uuid4

import pytest

from tests.conftest import assert_api_response_security


@pytest.mark.integration
@pytest.mark.api
class TestEvidenceClassificationAPI:
    """Test evidence classification API endpoints"""

    @pytest.fixture
    def sample_evidence_data(self):
        """Sample evidence data for testing."""
        return {
            "evidence_name": "Security Policy Document",
            "description": "Comprehensive information security policy covering access controls and data protection",
            "evidence_type": "unknown",
            "raw_data": json.dumps(
                {
                    "file_type": "pdf",
                    "content": "This policy establishes security controls...",
                }
            ),
        }

    def test_classify_single_evidence(
        self,
        client,
        authenticated_headers,
        sample_business_profile,
        sample_evidence_data,
    ):
        """Test classifying a single evidence item."""
        # First create evidence
        create_response = client.post(
            "/api/evidence/", json=sample_evidence_data, headers=authenticated_headers
        )

        if create_response.status_code != 200:
            pytest.skip("Evidence creation failed - may need business profile setup")

        evidence_id = create_response.json()["id"]

        # Mock AI classification
        with patch(
            "services.automation.evidence_processor.EvidenceProcessor._ai_classify_evidence"
        ) as mock_ai:
            mock_ai.return_value = {
                "suggested_type": "policy_document",
                "confidence": 85,
                "suggested_controls": ["A.5.1.1", "A.5.1.2", "A.9.1.1"],
                "reasoning": "Document contains policy language and security controls",
            }

            # Test classification
            classify_request = {"evidence_id": evidence_id, "force_reclassify": False}

            response = client.post(
                f"/api/evidence/{evidence_id}/classify",
                json=classify_request,
                headers=authenticated_headers,
            )

            assert response.status_code == 200
            assert_api_response_security(response)

            response_data = response.json()
            assert response_data["evidence_id"] == evidence_id
            assert response_data["confidence"] == 85
            assert response_data["suggested_controls"] == [
                "A.5.1.1",
                "A.5.1.2",
                "A.9.1.1",
            ]
            assert response_data["apply_suggestion"] is True  # High confidence

    def test_classify_evidence_force_reclassify(
        self,
        client,
        authenticated_headers,
        sample_business_profile,
        sample_evidence_data,
    ):
        """Test force reclassification of already classified evidence."""
        # Create evidence
        create_response = client.post(
            "/api/evidence/", json=sample_evidence_data, headers=authenticated_headers
        )

        if create_response.status_code != 200:
            pytest.skip("Evidence creation failed")

        evidence_id = create_response.json()["id"]

        with patch(
            "services.automation.evidence_processor.EvidenceProcessor._ai_classify_evidence"
        ) as mock_ai:
            # First classification
            mock_ai.return_value = {
                "suggested_type": "policy_document",
                "confidence": 85,
                "suggested_controls": ["A.5.1.1"],
                "reasoning": "Initial classification",
            }

            # Classify first time
            response1 = client.post(
                f"/api/evidence/{evidence_id}/classify",
                json={"evidence_id": evidence_id, "force_reclassify": False},
                headers=authenticated_headers,
            )

            if response1.status_code == 200:
                # Second classification with different result
                mock_ai.return_value = {
                    "suggested_type": "audit_report",
                    "confidence": 90,
                    "suggested_controls": ["A.9.2.1"],
                    "reasoning": "Reclassified as audit report",
                }

                # Should use cached result without force_reclassify
                response2 = client.post(
                    f"/api/evidence/{evidence_id}/classify",
                    json={"evidence_id": evidence_id, "force_reclassify": False},
                    headers=authenticated_headers,
                )

                if response2.status_code == 200:
                    assert response2.json()["reasoning"] == "Previously classified"

                # Should reclassify with force_reclassify
                response3 = client.post(
                    f"/api/evidence/{evidence_id}/classify",
                    json={"evidence_id": evidence_id, "force_reclassify": True},
                    headers=authenticated_headers,
                )

                if response3.status_code == 200:
                    assert (
                        response3.json()["reasoning"] == "Reclassified as audit report"
                    )

    def test_bulk_classify_evidence(
        self, client, authenticated_headers, sample_business_profile
    ):
        """Test bulk classification of multiple evidence items."""
        # Create multiple evidence items
        evidence_ids = []
        for i in range(3):
            evidence_data = {
                "evidence_name": f"Test Evidence {i}",
                "description": f"Test description {i}",
                "evidence_type": "unknown",
            }

            create_response = client.post(
                "/api/evidence/", json=evidence_data, headers=authenticated_headers
            )

            if create_response.status_code == 200:
                evidence_ids.append(create_response.json()["id"])

        if not evidence_ids:
            pytest.skip("No evidence items created successfully")

        # Mock AI classification
        with patch(
            "services.automation.evidence_processor.EvidenceProcessor._ai_classify_evidence"
        ) as mock_ai:
            mock_ai.return_value = {
                "suggested_type": "policy_document",
                "confidence": 75,
                "suggested_controls": ["A.5.1.1"],
                "reasoning": "Bulk classification test",
            }

            # Test bulk classification
            bulk_request = {
                "evidence_ids": evidence_ids,
                "force_reclassify": False,
                "apply_high_confidence": True,
                "confidence_threshold": 70,
            }

            response = client.post(
                "/api/evidence/classify/bulk",
                json=bulk_request,
                headers=authenticated_headers,
            )

            assert response.status_code == 200
            assert_api_response_security(response)

            response_data = response.json()
            assert response_data["total_processed"] == len(evidence_ids)
            assert response_data["successful_classifications"] > 0
            assert (
                response_data["auto_applied"] > 0
            )  # Should auto-apply due to confidence >= 70

    def test_get_control_mapping_suggestions(
        self,
        client,
        authenticated_headers,
        sample_business_profile,
        sample_evidence_data,
    ):
        """Test getting control mapping suggestions for evidence."""
        # Create evidence
        create_response = client.post(
            "/api/evidence/", json=sample_evidence_data, headers=authenticated_headers
        )

        if create_response.status_code != 200:
            pytest.skip("Evidence creation failed")

        evidence_id = create_response.json()["id"]

        # Mock AI classification
        with patch(
            "services.automation.evidence_processor.EvidenceProcessor._ai_classify_evidence"
        ) as mock_ai:
            mock_ai.return_value = {
                "suggested_type": "policy_document",
                "confidence": 85,
                "suggested_controls": ["A.5.1.1", "CC6.1", "Art. 32"],
                "reasoning": "Multi-framework control mapping",
            }

            # Test control mapping
            mapping_request = {
                "evidence_id": evidence_id,
                "frameworks": ["ISO27001", "SOC2", "GDPR"],
            }

            response = client.post(
                f"/api/evidence/{evidence_id}/control-mapping",
                json=mapping_request,
                headers=authenticated_headers,
            )

            assert response.status_code == 200
            assert_api_response_security(response)

            response_data = response.json()
            assert response_data["evidence_id"] == evidence_id
            assert "framework_mappings" in response_data
            assert "ISO27001" in response_data["framework_mappings"]
            assert "SOC2" in response_data["framework_mappings"]
            assert "GDPR" in response_data["framework_mappings"]

    def test_get_classification_statistics(
        self, client, authenticated_headers, sample_business_profile
    ):
        """Test getting classification statistics."""
        response = client.get(
            "/api/evidence/classification/stats", headers=authenticated_headers
        )

        assert response.status_code == 200
        assert_api_response_security(response)

        response_data = response.json()
        assert "total_evidence" in response_data
        assert "classified_evidence" in response_data
        assert "unclassified_evidence" in response_data
        assert "classification_accuracy" in response_data
        assert "type_distribution" in response_data
        assert "confidence_distribution" in response_data
        assert "recent_classifications" in response_data

        # Verify data consistency
        assert (
            response_data["classified_evidence"]
            + response_data["unclassified_evidence"]
            == response_data["total_evidence"]
        )

    def test_classify_nonexistent_evidence(self, client, authenticated_headers):
        """Test classifying non-existent evidence returns 404."""
        fake_evidence_id = str(uuid4())

        classify_request = {"evidence_id": fake_evidence_id, "force_reclassify": False}

        response = client.post(
            f"/api/evidence/{fake_evidence_id}/classify",
            json=classify_request,
            headers=authenticated_headers,
        )

        assert response.status_code == 404

    def test_bulk_classify_with_invalid_evidence(self, client, authenticated_headers):
        """Test bulk classification with some invalid evidence IDs."""
        fake_evidence_id = str(uuid4())

        bulk_request = {
            "evidence_ids": [fake_evidence_id],
            "force_reclassify": False,
            "apply_high_confidence": True,
            "confidence_threshold": 70,
        }

        response = client.post(
            "/api/evidence/classify/bulk",
            json=bulk_request,
            headers=authenticated_headers,
        )

        assert response.status_code == 200  # Should handle gracefully
        response_data = response.json()
        assert response_data["failed_classifications"] > 0
        assert len(response_data["results"]) == 1
        assert response_data["results"][0]["success"] is False


@pytest.mark.integration
@pytest.mark.api
class TestEvidenceClassificationValidation:
    """Test validation and error handling for classification endpoints"""

    def test_bulk_classify_too_many_items(self, client, authenticated_headers):
        """Test bulk classification with too many evidence items."""
        # Create request with more than 50 items (the limit)
        evidence_ids = [str(uuid4()) for _ in range(51)]

        bulk_request = {"evidence_ids": evidence_ids, "force_reclassify": False}

        response = client.post(
            "/api/evidence/classify/bulk",
            json=bulk_request,
            headers=authenticated_headers,
        )

        assert response.status_code == 422  # Validation error

    def test_invalid_confidence_threshold(self, client, authenticated_headers):
        """Test bulk classification with invalid confidence threshold."""
        bulk_request = {
            "evidence_ids": [str(uuid4())],
            "confidence_threshold": 150,  # Invalid - should be 0-100
        }

        response = client.post(
            "/api/evidence/classify/bulk",
            json=bulk_request,
            headers=authenticated_headers,
        )

        assert response.status_code == 422  # Validation error

    def test_classification_ai_service_error(
        self, client, authenticated_headers, sample_business_profile
    ):
        """Test handling of AI service errors during classification."""
        # Create evidence
        evidence_data = {
            "evidence_name": "Test Evidence",
            "description": "Test description",
            "evidence_type": "unknown",
        }

        create_response = client.post(
            "/api/evidence/", json=evidence_data, headers=authenticated_headers
        )

        if create_response.status_code != 200:
            pytest.skip("Evidence creation failed")

        evidence_id = create_response.json()["id"]

        # Mock AI service failure
        with patch(
            "services.automation.evidence_processor.EvidenceProcessor._ai_classify_evidence"
        ) as mock_ai:
            mock_ai.side_effect = Exception("AI service temporarily unavailable")

            response = client.post(
                f"/api/evidence/{evidence_id}/classify",
                json={"evidence_id": evidence_id, "force_reclassify": False},
                headers=authenticated_headers,
            )

            assert response.status_code == 500
