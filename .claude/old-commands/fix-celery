#!/bin/bash
# Fix Celery with LangGraph persistence

cat << 'EOF'
═══════════════════════════════════════════════════════════════
ISSUE #3: Fragmented Asynchronous Task Management
═══════════════════════════════════════════════════════════════

PROBLEM: Using Celery for long-running tasks instead of LangGraph persistence

FILES TO CHECK:
- celery_app.py
- workers/
- Any file with "@celery" or ".delay()"
- main.py (for Celery initialization)

REPLACE CELERY TASKS WITH THIS:
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
from langgraph.checkpoint.sqlite import SqliteSaver
from langgraph.graph import StateGraph, END
from typing import Optional
import uuid

class PersistentTaskProcessor:
    """Replaces all Celery tasks."""
    
    def __init__(self):
        self.checkpointer = SqliteSaver.from_conn_string("tasks.db")
    
    def create_task_graph(self) -> StateGraph:
        """Convert Celery tasks to LangGraph nodes."""
        graph = StateGraph(GraphState)
        
        # Replace each @celery_app.task with a node:
        graph.add_node("load_data", self.load_data_node)
        graph.add_node("process_data", self.process_data_node) 
        graph.add_node("save_results", self.save_results_node)
        
        # Define flow (was Celery chain/group)
        graph.set_entry_point("load_data")
        graph.add_edge("load_data", "process_data")
        graph.add_edge("process_data", "save_results")
        graph.add_edge("save_results", END)
        
        return graph.compile(checkpointer=self.checkpointer)
    
    async def load_data_node(self, state: GraphState) -> GraphState:
        """Was @celery_app.task def load_data_task()"""
        # Original Celery task logic here
        state["current_step"] = "process_data"
        state["metadata"]["data_loaded"] = True
        return state
    
    async def process_data_node(self, state: GraphState) -> GraphState:
        """Was @celery_app.task def process_data_task()"""
        # Original Celery task logic here
        state["current_step"] = "save_results"
        return state
    
    async def save_results_node(self, state: GraphState) -> GraphState:
        """Was @celery_app.task def save_results_task()"""
        # Original Celery task logic here
        state["current_step"] = "completed"
        return state
    
    async def process(self, data: dict, task_id: Optional[str] = None):
        """Replaces task.delay() or task.apply_async()"""
        if not task_id:
            task_id = str(uuid.uuid4())
        
        config = {"configurable": {"thread_id": task_id}}
        graph = self.create_task_graph()
        
        # Check if resuming (was Celery result backend)
        state = graph.get_state(config)
        if state.values:
            # Resume from checkpoint
            return await graph.ainvoke(None, config)
        else:
            # Start new task
            return await graph.ainvoke(data, config)
    
    def get_status(self, task_id: str) -> dict:
        """Replaces AsyncResult(task_id).status"""
        config = {"configurable": {"thread_id": task_id}}
        graph = self.create_task_graph()
        state = graph.get_state(config)
        
        if not state.values:
            return {"status": "NOT_FOUND"}
        
        current_step = state.values.get("current_step", "unknown")
        if current_step == "completed":
            return {"status": "SUCCESS", "result": state.values}
        elif current_step == "failed":
            return {"status": "FAILURE", "error": state.values.get("errors")}
        else:
            return {"status": "PENDING", "current_step": current_step}

REPLACE API ENDPOINTS:
━━━━━━━━━━━━━━━━━━━━━
# OLD Celery way:
@app.post("/process")
async def process_endpoint(data: dict):
    task = celery_task.delay(data)
    return {"task_id": task.id}

# NEW LangGraph way:
processor = PersistentTaskProcessor()

@app.post("/process")
async def process_endpoint(data: dict):
    task_id = str(uuid.uuid4())
    result = await processor.process(data, task_id)
    return {"task_id": task_id, "status": "started"}

@app.get("/status/{task_id}")
async def get_status(task_id: str):
    return processor.get_status(task_id)

DELETE THESE:
━━━━━━━━━━━━━
- from celery import Celery
- celery_app = Celery(...)
- @celery_app.task
- .delay()
- .apply_async()
- AsyncResult
- celery_app.conf.update(...)
- All Celery configuration
EOF
