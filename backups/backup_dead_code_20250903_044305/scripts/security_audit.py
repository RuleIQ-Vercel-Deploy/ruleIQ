"""
from __future__ import annotations
import logging
logger = logging.getLogger(__name__)

Comprehensive Security Audit Script for ruleIQ Backend Fixes
Performs automated security testing and validation
"""

import os
import sys
import json
from datetime import datetime
from typing import Dict, Any


class SecurityAuditor:
    """Automated security audit for backend fixes"""

    def __init__(self) ->None:
        self.results = {'timestamp': datetime.now().isoformat(), 'summary':
            {'total_checks': 0, 'passed': 0, 'failed': 0, 'warnings': 0},
            'details': []}

    def log_result(self, check_name: str, status: str, details: str='') ->None:
        """Log audit result"""
        self.results['summary']['total_checks'] += 1
        if status == 'PASS':
            self.results['summary']['passed'] += 1
        elif status == 'FAIL':
            self.results['summary']['failed'] += 1
        elif status == 'WARN':
            self.results['summary']['warnings'] += 1
        self.results['details'].append({'check': check_name, 'status':
            status, 'details': details})

    def check_environment_variables(self) ->bool:
        """Check for secure environment variable configuration"""
        required_vars = ['SECRET_KEY', 'DATABASE_URL', 'REDIS_URL']
        for var in required_vars:
            if not os.getenv(var):
                self.log_result(f'Environment Variable: {var}', 'FAIL',
                    f'Missing required environment variable: {var}')
                return False
        secret_key = os.getenv('SECRET_KEY', '')
        if len(secret_key) < 32 or 'your-secret-key' in secret_key.lower():
            self.log_result('SECRET_KEY Strength', 'FAIL',
                'SECRET_KEY is too weak or uses default value')
            return False
        self.log_result('Environment Variables', 'PASS',
            'All required environment variables are configured')
        return True

    def check_file_permissions(self) ->bool:
        """Check file permissions for sensitive files"""
        sensitive_files = ['.env', 'config/security_config.py',
            'core/security/credential_encryption.py']
        all_secure = True
        for file_path in sensitive_files:
            if os.path.exists(file_path):
                stat = os.stat(file_path)
                if stat.st_mode & 36:
                    self.log_result(f'File Permissions: {file_path}',
                        'FAIL',
                        f'File is readable by others: {oct(stat.st_mode)[-3:]}',
                        )
                    all_secure = False
        if all_secure:
            self.log_result('File Permissions', 'PASS',
                'All sensitive files have secure permissions')
        return all_secure

    def check_security_headers(self) ->bool:
        """Check security headers are properly configured"""
        try:
            with open('api/middleware/security_middleware.py', 'r') as f:
                content = f.read()
            required_headers = ['X-Content-Type-Options', 'X-Frame-Options',
                'X-XSS-Protection', 'Strict-Transport-Security']
            missing_headers = []
            for header in required_headers:
                if header not in content:
                    missing_headers.append(header)
            if missing_headers:
                self.log_result('Security Headers', 'FAIL',
                    f'Missing security headers: {missing_headers}')
                return False
            self.log_result('Security Headers', 'PASS',
                'All required security headers are configured')
            return True
        except Exception as e:
            self.log_result('Security Headers Check', 'WARN',
                f'Could not verify security headers: {str(e)}')
            return False

    def check_input_validation(self) ->bool:
        """Check input validation is implemented"""
        try:
            with open('api/utils/input_validation.py', 'r') as f:
                content = f.read()
            validation_patterns = ['sanitize_input', 'validate_email',
                'validate_file_type', 'sql_injection_check']
            missing_patterns = []
            for pattern in validation_patterns:
                if pattern not in content:
                    missing_patterns.append(pattern)
            if missing_patterns:
                self.log_result('Input Validation', 'WARN',
                    f'Missing validation patterns: {missing_patterns}')
                return False
            self.log_result('Input Validation', 'PASS',
                'Input validation is properly implemented')
            return True
        except Exception as e:
            self.log_result('Input Validation Check', 'WARN',
                f'Could not verify input validation: {str(e)}')
            return False

    def check_rate_limiting(self) ->bool:
        """Check rate limiting is configured"""
        try:
            with open('api/middleware/rate_limiter.py', 'r') as f:
                content = f.read()
            if 'RateLimiter' not in content:
                self.log_result('Rate Limiting', 'FAIL',
                    'Rate limiting middleware not found')
                return False
            self.log_result('Rate Limiting', 'PASS',
                'Rate limiting is configured')
            return True
        except Exception as e:
            self.log_result('Rate Limiting Check', 'WARN',
                f'Could not verify rate limiting: {str(e)}')
            return False

    def check_database_security(self) ->bool:
        """Check database security measures"""
        try:
            with open('database/query_optimization.py', 'r') as f:
                content = f.read()
            if 'text(' in content or 'bindparams' in content:
                self.log_result('Database Security', 'PASS',
                    'Parameterized queries are used')
                return True
            else:
                self.log_result('Database Security', 'WARN',
                    'Could not verify parameterized queries')
                return False
        except Exception as e:
            self.log_result('Database Security Check', 'WARN',
                f'Could not verify database security: {str(e)}')
            return False

    def check_error_handling(self) ->bool:
        """Check error handling doesn't expose sensitive data"""
        try:
            with open('api/utils/error_handlers.py', 'r') as f:
                content = f.read()
            sensitive_patterns = ['password', 'secret', 'key', 'token']
            redaction_found = False
            for pattern in sensitive_patterns:
                if f'REDACTED_{pattern.upper()}' in content:
                    redaction_found = True
                    break
            if redaction_found:
                self.log_result('Error Handling Security', 'PASS',
                    'Sensitive data is redacted in error messages')
                return True
            else:
                self.log_result('Error Handling Security', 'WARN',
                    'Could not verify sensitive data redaction')
                return False
        except Exception as e:
            self.log_result('Error Handling Check', 'WARN',
                f'Could not verify error handling: {str(e)}')
            return False

    def check_credential_encryption(self) ->bool:
        """Check credential encryption is implemented"""
        try:
            with open('core/security/credential_encryption.py', 'r') as f:
                content = f.read()
            encryption_patterns = ['encrypt', 'decrypt', 'fernet',
                'cryptography']
            missing_patterns = []
            for pattern in encryption_patterns:
                if pattern not in content.lower():
                    missing_patterns.append(pattern)
            if missing_patterns:
                self.log_result('Credential Encryption', 'FAIL',
                    f'Missing encryption patterns: {missing_patterns}')
                return False
            self.log_result('Credential Encryption', 'PASS',
                'Credential encryption is implemented')
            return True
        except Exception as e:
            self.log_result('Credential Encryption Check', 'WARN',
                f'Could not verify credential encryption: {str(e)}')
            return False

    def run_comprehensive_audit(self) ->Dict[str, Any]:
        """Run all security audit checks"""
        logger.info('üîç Starting Comprehensive Security Audit...')
        logger.info('=' * 50)
        checks = [('Environment Variables', self.
            check_environment_variables), ('File Permissions', self.
            check_file_permissions), ('Security Headers', self.
            check_security_headers), ('Input Validation', self.
            check_input_validation), ('Rate Limiting', self.
            check_rate_limiting), ('Database Security', self.
            check_database_security), ('Error Handling', self.
            check_error_handling), ('Credential Encryption', self.
            check_credential_encryption)]
        for check_name, check_func in checks:
            logger.info('Checking %s...' % check_name)
            check_func()
        logger.info('=' * 50)
        logger.info('üìä Security Audit Summary')
        logger.info('Total Checks: %s' % self.results['summary'][
            'total_checks'])
        logger.info('Passed: %s' % self.results['summary']['passed'])
        logger.info('Failed: %s' % self.results['summary']['failed'])
        logger.info('Warnings: %s' % self.results['summary']['warnings'])
        with open('security_audit_report.json', 'w') as f:
            json.dump(self.results, f, indent=2)
        return self.results

    def generate_report(self) ->str:
        """Generate human-readable security report"""
        report = f"""
# Security Audit Report
Generated: {self.results['timestamp']}

## Summary
- Total Checks: {self.results['summary']['total_checks']}
- Passed: {self.results['summary']['passed']}
- Failed: {self.results['summary']['failed']}
- Warnings: {self.results['summary']['warnings']}

## Detailed Results
"""
        for detail in self.results['details']:
            status_emoji = {'PASS': '‚úÖ', 'FAIL': '‚ùå', 'WARN': '‚ö†Ô∏è'}
            report += (
                f"\n### {status_emoji[detail['status']]} {detail['check']}\n")
            report += f"Status: {detail['status']}\n"
            if detail['details']:
                report += f"Details: {detail['details']}\n"
        return report


def main() ->None:
    """Main audit execution"""
    auditor = SecurityAuditor()
    results = auditor.run_comprehensive_audit()
    report = auditor.generate_report()
    with open('SECURITY_AUDIT_REPORT.md', 'w') as f:
        f.write(report)
    logger.info('\nüìã Security audit completed!')
    logger.info('üìÑ Report saved to: SECURITY_AUDIT_REPORT.md')
    logger.info('üìä JSON results saved to: security_audit_report.json')
    if results['summary']['failed'] > 0:
        logger.info('\n‚ùå Security audit failed - please address failed checks')
        sys.exit(1)
    elif results['summary']['warnings'] > 0:
        logger.info('\n‚ö†Ô∏è Security audit passed with warnings')
        sys.exit(0)
    else:
        logger.info('\n‚úÖ Security audit passed successfully')
        sys.exit(0)


if __name__ == '__main__':
    main()
