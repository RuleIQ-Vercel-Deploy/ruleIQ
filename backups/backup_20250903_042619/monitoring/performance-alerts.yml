# Performance Monitoring Alerts Configuration
# Alert rules for production monitoring

groups:
  - name: frontend_performance
    rules:
      - alert: HighResponseTime
        expr: http_request_duration_seconds{quantile="0.95"} > 2
        for: 5m
        labels:
          severity: warning
          component: frontend
        annotations:
          summary: "High response time detected"
          description: "95th percentile response time is {{ $value }}s for {{ $labels.endpoint }}"

      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.05
        for: 2m
        labels:
          severity: critical
          component: frontend
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }} for {{ $labels.endpoint }}"

      - alert: CoreWebVitalsDegradation
        expr: |
          (
            lcp_seconds > 4 or
            fid_seconds > 0.3 or
            cls_score > 0.25
          )
        for: 10m
        labels:
          severity: warning
          component: frontend
        annotations:
          summary: "Core Web Vitals degradation"
          description: "{{ $labels.metric }} is {{ $value }} for {{ $labels.page }}"

  - name: database_performance
    rules:
      - alert: SlowQueryAlert
        expr: pg_stat_statements_mean_time > 1000
        for: 5m
        labels:
          severity: warning
          component: database
        annotations:
          summary: "Slow query detected"
          description: "Query {{ $labels.query }} has mean time {{ $value }}ms"

      - alert: HighConnectionUsage
        expr: pg_stat_activity_count / pg_settings_max_connections > 0.8
        for: 2m
        labels:
          severity: warning
          component: database
        annotations:
          summary: "High database connection usage"
          description: "Database connections at {{ $value | humanizePercentage }} capacity"

      - alert: LowCacheHitRatio
        expr: pg_stat_database_blks_hit / (pg_stat_database_blks_hit + pg_stat_database_blks_read) < 0.9
        for: 10m
        labels:
          severity: warning
          component: database
        annotations:
          summary: "Low cache hit ratio"
          description: "Database cache hit ratio is {{ $value | humanizePercentage }}"

  - name: infrastructure_performance
    rules:
      - alert: HighCPUUsage
        expr: cpu_usage_percent > 80
        for: 5m
        labels:
          severity: warning
          component: infrastructure
        annotations:
          summary: "High CPU usage"
          description: "CPU usage is {{ $value }}% on {{ $labels.instance }}"

      - alert: HighMemoryUsage
        expr: memory_usage_percent > 85
        for: 5m
        labels:
          severity: warning
          component: infrastructure
        annotations:
          summary: "High memory usage"
          description: "Memory usage is {{ $value }}% on {{ $labels.instance }}"

      - alert: HighDiskUsage
        expr: disk_usage_percent > 90
        for: 5m
        labels:
          severity: critical
          component: infrastructure
        annotations:
          summary: "High disk usage"
          description: "Disk usage is {{ $value }}% on {{ $labels.instance }}"

  - name: load_testing_alerts
    rules:
      - alert: LoadTestFailure
        expr: k6_test_success != 1
        for: 0m
        labels:
          severity: warning
          component: load_testing
        annotations:
          summary: "Load test failed"
          description: "Load test {{ $labels.test_name }} failed with status {{ $value }}"

      - alert: PerformanceRegression
        expr: |
          (
            k6_http_req_duration_p95 > 2000 or
            k6_http_req_failed_rate > 0.05
          )
        for: 0m
        labels:
          severity: warning
          component: load_testing
        annotations:
          summary: "Performance regression detected"
          description: "{{ $labels.metric }} is {{ $value }} in load test {{ $labels.test_name }}"

  - name: security_alerts
    rules:
      - alert: SecurityScanFailure
        expr: security_scan_score < 80
        for: 0m
        labels:
          severity: warning
          component: security
        annotations:
          summary: "Security scan failure"
          description: "Security scan score is {{ $value }} for {{ $labels.scan_type }}"

      - alert: HighVulnerabilityCount
        expr: security_vulnerabilities_total{severity="high"} > 0
        for: 0m
        labels:
          severity: critical
          component: security
        annotations:
          summary: "High severity vulnerabilities detected"
          description: "{{ $value }} high severity vulnerabilities found"

# Notification channels
notification_channels:
  slack:
    webhook_url: "${SLACK_WEBHOOK_URL}"
    channel: "#alerts"

  email:
    smtp_server: "${SMTP_SERVER}"
    smtp_port: 587
    username: "${SMTP_USERNAME}"
    password: "${SMTP_PASSWORD}"
    from: "alerts@ruleiq.com"
    to: ["dev-team@ruleiq.com", "ops-team@ruleiq.com"]

  pagerduty:
    service_key: "${PAGERDUTY_SERVICE_KEY}"

# Escalation policies
escalation_policies:
  frontend_critical:
    - notify: ["on-call-frontend"]
    - wait: 5m
    - notify: ["frontend-team-lead"]
    - wait: 10m
    - notify: ["engineering-manager"]

  database_critical:
    - notify: ["on-call-database"]
    - wait: 2m
    - notify: ["database-team-lead"]
    - wait: 5m
    - notify: ["engineering-manager"]

  security_critical:
    - notify: ["on-call-security"]
    - wait: 0m
    - notify: ["security-team-lead"]
    - wait: 5m
    - notify: ["ciso"]
