============================= test session starts ==============================
platform linux -- Python 3.12.3, pytest-8.4.1, pluggy-1.6.0 -- /usr/bin/python3
cachedir: .pytest_cache
benchmark: 5.1.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)
rootdir: /home/omar/Documents/ruleIQ
configfile: pytest.ini
plugins: anyio-4.10.0, langsmith-0.4.20, dotenv-0.5.2, asyncio-1.1.0, benchmark-5.1.0
asyncio: mode=Mode.AUTO, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
collecting ... 
----------------------------- live log collection ------------------------------
2025-08-29 08:11:42 [ WARNING] config.settings: Google API key may not be in the correct format (should start with 'AIza')
collected 1526 items

tests/ai/test_compliance_accuracy.py::TestComplianceAccuracy::test_gdpr_basic_questions_accuracy ERROR [  0%]

==================================== ERRORS ====================================
_ ERROR at setup of TestComplianceAccuracy.test_gdpr_basic_questions_accuracy __
file /home/omar/Documents/ruleIQ/tests/ai/test_compliance_accuracy.py, line 32
      @pytest.mark.asyncio
      async def test_gdpr_basic_questions_accuracy(
          self,
          async_db_session,
          mock_ai_client,
          gdpr_golden_dataset,
          async_sample_user,
          async_sample_business_profile,
      ):
          """Test AI accuracy on basic GDPR questions"""
          assistant = ComplianceAssistant(async_db_session)

          basic_questions = [q for q in gdpr_golden_dataset if q["difficulty"] == "basic"]
          correct_answers = 0
          total_questions = len(basic_questions)

          for question_data in basic_questions:
              # Mock AI response with realistic compliance content
              mock_response = self._generate_mock_response(question_data)
              mock_ai_client.generate_content.return_value.text = mock_response

              with patch.object(assistant, "process_message") as mock_process:
                  mock_process.return_value = (
                      mock_response,
                      {
                          "intent": "compliance_guidance",
                          "framework": question_data["framework"],
                          "confidence": 0.9,
                      },
                  )

                  response, metadata = await assistant.process_message(
                      conversation_id=uuid4(),
                      user=async_sample_user,
                      message=question_data["question"],
                      business_profile_id=async_sample_business_profile.id,
                  )

                  # Check if response contains expected keywords
                  if self._validate_response_accuracy(response, question_data):
                      correct_answers += 1

          # Require 85% accuracy on basic questions
          accuracy = correct_answers / total_questions
          assert accuracy >= 0.85, (
              f"Basic GDPR accuracy too low: {accuracy:.2%} ({correct_answers}/{total_questions})"
          )
E       fixture 'async_db_session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, benchmark, benchmark_weave, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, clean_test_db, db_session, doctest_namespace, event_loop, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, gdpr_golden_dataset, mock_llm, monkeypatch, postgres_checkpointer, postgres_connection, postgres_test_url, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/omar/Documents/ruleIQ/tests/ai/test_compliance_accuracy.py:32
=============================== warnings summary ===============================
tests/utils/auth_test_utils.py:14
  /home/omar/Documents/ruleIQ/tests/utils/auth_test_utils.py:14: PytestCollectionWarning: cannot collect test class 'TestAuthManager' because it has a __init__ constructor (from: tests/integration/test_comprehensive_api_workflows.py)
    class TestAuthManager:

tests/utils/auth_test_utils.py:14
  /home/omar/Documents/ruleIQ/tests/utils/auth_test_utils.py:14: PytestCollectionWarning: cannot collect test class 'TestAuthManager' because it has a __init__ constructor (from: tests/integration/test_contract_validation.py)
    class TestAuthManager:

tests/utils/auth_test_utils.py:14
  /home/omar/Documents/ruleIQ/tests/utils/auth_test_utils.py:14: PytestCollectionWarning: cannot collect test class 'TestAuthManager' because it has a __init__ constructor (from: tests/integration/test_external_service_integration.py)
    class TestAuthManager:

tests/monitoring/test_metrics.py:17
  /home/omar/Documents/ruleIQ/tests/monitoring/test_metrics.py:17: PytestCollectionWarning: cannot collect test class 'TestMetricsCollector' because it has a __init__ constructor (from: tests/monitoring/test_metrics.py)
    class TestMetricsCollector:

tests/fixtures/state_fixtures.py:20
  /home/omar/Documents/ruleIQ/tests/fixtures/state_fixtures.py:20: PytestCollectionWarning: cannot collect test class 'TestScenario' because it has a __init__ constructor (from: tests/test_graph_execution.py)
    class TestScenario(Enum):

tests/test_simple_settings.py:33
  /home/omar/Documents/ruleIQ/tests/test_simple_settings.py:33: PytestCollectionWarning: cannot collect test class 'TestSettings' because it has a __init__ constructor (from: tests/test_simple_settings.py)
    class TestSettings(BaseSettings):

tests/fixtures/state_fixtures.py:20
  /home/omar/Documents/ruleIQ/tests/fixtures/state_fixtures.py:20: PytestCollectionWarning: cannot collect test class 'TestScenario' because it has a __init__ constructor (from: tests/test_state_management.py)
    class TestScenario(Enum):

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
============================= slowest 10 durations =============================

(2 durations < 0.005s hidden.  Use -vv to show these durations.)
=========================== short test summary info ============================
ERROR tests/ai/test_compliance_accuracy.py::TestComplianceAccuracy::test_gdpr_basic_questions_accuracy
!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!
========================= 7 warnings, 1 error in 6.86s =========================
