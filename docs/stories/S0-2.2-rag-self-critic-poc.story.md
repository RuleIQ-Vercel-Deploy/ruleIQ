# Story S0-2.2: RAG Self-Critic PoC

## Status
In Progress

## Story
**As a** compliance officer,
**I want** AI responses to be automatically validated against our regulatory knowledge base,
**so that** I can trust the accuracy of automated compliance assessments with confidence scores.

## Acceptance Criteria
1. [ ] Validates AI responses against compliance knowledge base
2. [ ] Provides confidence scores (0-100%) for responses
3. [ ] Flags responses requiring human review (<80% confidence)
4. [ ] Processes validation in <100ms additional latency
5. [ ] Integrates with existing circuit breaker patterns
6. [ ] Maintains validation audit log for compliance tracking
7. [ ] Supports batch validation for multiple responses
8. [ ] Provides detailed validation failure reasons

## Tasks / Subtasks
- [ ] Build compliance knowledge base infrastructure (AC: 1)
  - [ ] Set up ChromaDB vector database for regulatory documents
  - [ ] Design document ingestion pipeline
  - [ ] Create embedding generation service using OpenAI/Gemini
  - [ ] Implement document chunking strategy (512 token chunks with 50 token overlap)
  - [ ] Add metadata extraction for regulations (date, jurisdiction, category)

- [ ] Implement response validation pipeline (AC: 2, 3, 4)
  - [ ] Create RAGValidator service class in `services/rag_validator.py`
  - [ ] Implement semantic similarity scoring using cosine similarity
  - [ ] Add confidence score calculation based on:
    - [ ] Semantic similarity to knowledge base (40% weight)
    - [ ] Citation coverage (30% weight)
    - [ ] Fact consistency checking (30% weight)
  - [ ] Create threshold configuration for confidence levels
  - [ ] Implement async validation to maintain <100ms latency

- [ ] Create human review flagging system (AC: 3, 8)
  - [ ] Design review queue data model in PostgreSQL
  - [ ] Implement flagging logic for low confidence responses
  - [ ] Create detailed failure reason categorization:
    - [ ] NO_MATCHING_REGULATION
    - [ ] CONFLICTING_INFORMATION
    - [ ] OUTDATED_REFERENCE
    - [ ] INSUFFICIENT_CONTEXT
  - [ ] Add priority scoring for review queue

- [ ] Integrate with circuit breaker patterns (AC: 5)
  - [ ] Extend existing circuit breaker in `middleware/circuit_breaker.py`
  - [ ] Add validation service health checks
  - [ ] Implement fallback to manual review when circuit opens
  - [ ] Configure thresholds: 5 failures in 60 seconds triggers circuit

- [ ] Implement validation audit logging (AC: 6)
  - [ ] Create audit log schema in `models/validation_audit.py`
  - [ ] Log all validation attempts with:
    - [ ] Request ID, timestamp, user context
    - [ ] Original response, validation result, confidence score
    - [ ] Processing time, failure reasons
  - [ ] Integrate with existing structured logging (structlog)

- [ ] Add batch validation support (AC: 7)
  - [ ] Create batch validation endpoint `/api/v1/ai/validate-batch`
  - [ ] Implement parallel processing using asyncio
  - [ ] Add rate limiting: max 10 responses per batch
  - [ ] Return aggregated validation results

- [ ] Create validation result models (AC: 2, 8)
  - [ ] Define Pydantic models in `models/validation.py`:
    - [ ] ValidationResult with confidence score, flags, reasons
    - [ ] ValidationMetrics for performance tracking
  - [ ] Add JSON serialization for API responses

- [ ] Write comprehensive tests
  - [ ] Unit tests for confidence scoring algorithms
  - [ ] Integration tests with mock knowledge base
  - [ ] Performance tests to validate <100ms latency
  - [ ] Edge case tests for malformed responses
  - [ ] Load tests for batch validation

## Dev Notes

### Relevant Architecture Information

**AI Stack Integration** [Source: architecture/tech-stack.md#ai-machine-learning]
- ChromaDB for vector database (RAG knowledge base)
- OpenAI API v1.0.0+ for embeddings generation
- Google Generative AI 0.8.0+ as alternative embedding model
- LangChain for orchestration if needed
- tiktoken 0.5.0+ for token counting

**Database Models** [Source: architecture/tech-stack.md#database-orm]
- PostgreSQL 13+ for validation audit logs and review queue
- Redis 7.0+ for caching validation results
- SQLAlchemy 2.0+ for ORM
- Alembic for migrations

**Existing Circuit Breaker Pattern**
- Located in `middleware/circuit_breaker.py`
- Current configuration: 5 failures in 60 seconds
- Fallback mechanism already implemented
- Health check endpoints available

**Performance Requirements**
- Target: <100ms additional latency for validation
- Use async processing with FastAPI
- Redis caching for frequently validated responses
- Connection pooling for database queries

**API Integration Points**
- Validation service should integrate with existing AI assessment endpoints
- Add validation middleware to `api/v1/assessments/ai-generate`
- Extend response models to include validation results

**File Locations for New Code**
- Service: `services/rag_validator.py`
- Models: `models/validation.py`, `models/validation_audit.py`
- API endpoints: `api/v1/ai/validation.py`
- Tests: `tests/services/test_rag_validator.py`
- Database migration: `alembic/versions/xxx_add_validation_tables.py`

### Testing Standards
[Source: architecture/coding-standards.md#testing]
- Test files location: `tests/` directory mirroring source structure
- Use pytest framework with fixtures
- Minimum 80% code coverage required
- Mock external services (ChromaDB, OpenAI) in unit tests
- Use `pytest-asyncio` for async test cases
- Performance tests use `pytest-benchmark`

### Previous Story Context
From S0-2.1 (Trust Level 0 Agent):
- Agent orchestrator is available at `services/agents/orchestrator.py`
- WebSocket communication established for real-time updates
- Session management using Redis
- Trust level validation already implemented

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-11 | 1.0 | Initial story creation | Bob (SM) |

## Dev Agent Record
*This section will be populated during implementation*

### Agent Model Used
*To be filled by dev agent*

### Debug Log References
*To be filled by dev agent*

### Completion Notes List
*To be filled by dev agent*

### File List
*To be filled by dev agent*

## QA Results
*This section will be populated during QA review*